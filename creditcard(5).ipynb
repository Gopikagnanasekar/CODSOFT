{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdugH777iIJLL4HJ4a1OV1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gopikagnanasekar/CODSOFT/blob/main/creditcard(5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "# !pip install scikit-learn  # No need to install if you already have it\n",
        "\n",
        "#loading the dataset to a Pandas DataFrame\n",
        "df = pd.read_csv('/content/creditcard.csv')\n",
        " # first 5 rows of the dataset\n",
        "df.head()\n",
        "df.tail() # dataset informations\n",
        "df.info()\n",
        " # checking the number of missing values in each column\n",
        "df.isnull().sum()\n",
        "# distribution of legit transactions & fraudulent transactions\n",
        "df['Class'].value_counts()\n",
        " # separating the data for analysis\n",
        "legit = df[df.Class == 0]\n",
        "fraud = df[df.Class == 1]\n",
        "print(legit.shape)\n",
        "print(fraud.shape)\n",
        " # statistical measures of the data\n",
        "legit.Amount.describe()\n",
        "fraud.Amount.describe()\n",
        "# compare the values for both transactions\n",
        "df.groupby('Class').mean()\n",
        "legit_sample = legit.sample(n=492)\n",
        "new_dataset = pd.concat([legit_sample, fraud], axis=0)\n",
        "new_dataset.head()\n",
        "new_dataset.tail()\n",
        "new_dataset['Class'].value_counts()\n",
        "new_dataset.groupby('Class').mean()\n",
        "X = new_dataset.drop(columns='Class', axis=1)  # Create X by dropping 'Class' column\n",
        "Y = new_dataset['Class']  # Create Y from 'Class' column\n",
        "print(X)\n",
        "print(Y)\n",
        "\n",
        "# Now you can split the data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n",
        "print(X.shape, X_train.shape, X_test.shape)\n",
        "model = LogisticRegression()\n",
        "# training the Logistic Regression Model with Training Data\n",
        "model.fit(X_train, Y_train)\n",
        "# accuracy on training data\n",
        "X_train_prediction = model.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
        "print('Accuracy on Training data : ', training_data_accuracy)\n",
        " # accuracy on test data\n",
        "X_test_prediction = model.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
        "print('Accuracy score on Test Data : ', test_data_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-8oUtRYHv2M",
        "outputId": "89dc5370-1077-425a-af8d-caf71a39ef8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9965 entries, 0 to 9964\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Time    9965 non-null   int64  \n",
            " 1   V1      9965 non-null   float64\n",
            " 2   V2      9965 non-null   float64\n",
            " 3   V3      9964 non-null   float64\n",
            " 4   V4      9964 non-null   float64\n",
            " 5   V5      9964 non-null   float64\n",
            " 6   V6      9964 non-null   float64\n",
            " 7   V7      9964 non-null   float64\n",
            " 8   V8      9964 non-null   float64\n",
            " 9   V9      9964 non-null   float64\n",
            " 10  V10     9964 non-null   float64\n",
            " 11  V11     9964 non-null   float64\n",
            " 12  V12     9964 non-null   float64\n",
            " 13  V13     9964 non-null   float64\n",
            " 14  V14     9964 non-null   float64\n",
            " 15  V15     9964 non-null   float64\n",
            " 16  V16     9964 non-null   float64\n",
            " 17  V17     9964 non-null   float64\n",
            " 18  V18     9964 non-null   float64\n",
            " 19  V19     9964 non-null   float64\n",
            " 20  V20     9964 non-null   float64\n",
            " 21  V21     9964 non-null   float64\n",
            " 22  V22     9964 non-null   float64\n",
            " 23  V23     9964 non-null   float64\n",
            " 24  V24     9964 non-null   float64\n",
            " 25  V25     9964 non-null   float64\n",
            " 26  V26     9964 non-null   float64\n",
            " 27  V27     9964 non-null   float64\n",
            " 28  V28     9964 non-null   float64\n",
            " 29  Amount  9964 non-null   float64\n",
            " 30  Class   9964 non-null   float64\n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 2.4 MB\n",
            "(9926, 31)\n",
            "(38, 31)\n",
            "       Time        V1        V2         V3         V4        V5        V6  \\\n",
            "4410   3767  1.458499 -0.589402  -0.881930  -1.640364  1.487446  3.264101   \n",
            "498     367  1.256217  0.255028   0.277716   0.706677 -0.495831 -1.106735   \n",
            "608     460 -2.264656 -0.707192   1.080243  -4.657545 -0.157183 -0.345406   \n",
            "4641   4015  1.234840  0.488604   0.588265   0.972211 -0.437607 -1.207239   \n",
            "4249   3754  1.113689 -0.873161   0.420723  -0.598428 -0.840675 -0.000932   \n",
            "...     ...       ...       ...        ...        ...       ...       ...   \n",
            "9035  12597 -2.589617  7.016714 -13.705407  10.343228 -2.954461 -3.055116   \n",
            "9179  13126 -2.880042  5.225442 -11.063330   6.689951 -5.759924 -2.244031   \n",
            "9252  13323 -5.454362  8.287421 -12.752811   8.594342 -3.106002 -3.179949   \n",
            "9487  14073 -4.153014  8.204797 -15.031714  10.330100 -3.994426 -3.250013   \n",
            "9509  14152 -4.710529  8.636214 -15.496222  10.313349 -4.351341 -3.322689   \n",
            "\n",
            "             V7        V8        V9  ...       V20       V21       V22  \\\n",
            "4410  -1.209634  0.718033  0.363593  ...  0.161813 -0.296035 -0.882646   \n",
            "498   -0.008493 -0.124504  0.243687  ... -0.171118 -0.303927 -0.943830   \n",
            "608    0.595042 -0.386704  2.211141  ... -0.164658 -0.632027  0.222079   \n",
            "4641   0.016873 -0.317816  1.262172  ... -0.118862 -0.413650 -0.938863   \n",
            "4249  -0.726528  0.048495  0.387771  ...  0.202917 -0.125305 -0.551246   \n",
            "...         ...       ...       ...  ...       ...       ...       ...   \n",
            "9035  -9.301289  3.349573 -5.654212  ...  1.488855  1.887738  0.333998   \n",
            "9179 -11.199975  4.014722 -3.429304  ...  1.191444  2.002883  0.351102   \n",
            "9252  -9.252794  4.245062 -6.329801  ...  1.305862  1.846165 -0.267172   \n",
            "9487 -10.415698  4.620804 -5.711248  ...  1.412625  1.976988  0.256510   \n",
            "9509 -10.788373  5.060381 -5.689311  ...  1.434240  1.990545  0.223785   \n",
            "\n",
            "           V23       V24       V25       V26       V27       V28  Amount  \n",
            "4410  0.107318  0.918503  0.367891 -0.505226 -0.014341  0.010290   12.38  \n",
            "498   0.146551  0.307164  0.169070  0.099129 -0.032095  0.027743    1.29  \n",
            "608  -0.189412 -0.332603  0.050197 -1.168870 -0.208793 -0.486754   50.78  \n",
            "4641  0.178005  0.616455  0.156507  0.034789 -0.048129  0.028335    2.68  \n",
            "4249  0.027925 -0.413839  0.073320 -0.496913 -0.032766  0.018345  129.08  \n",
            "...        ...       ...       ...       ...       ...       ...     ...  \n",
            "9035  0.287659 -1.186406 -0.690273  0.631704  1.934221  0.789687    1.00  \n",
            "9179  0.795255 -0.778379 -1.646815  0.487539  1.427713  0.583172    1.00  \n",
            "9252 -0.310804 -1.201685  1.352176  0.608425  1.574715  0.808725    1.00  \n",
            "9487  0.485908 -1.198821 -0.526567  0.634874  1.627209  0.723235    1.00  \n",
            "9509  0.554408 -1.204042 -0.450685  0.641836  1.605958  0.721644    1.00  \n",
            "\n",
            "[530 rows x 30 columns]\n",
            "4410    0.0\n",
            "498     0.0\n",
            "608     0.0\n",
            "4641    0.0\n",
            "4249    0.0\n",
            "       ... \n",
            "9035    1.0\n",
            "9179    1.0\n",
            "9252    1.0\n",
            "9487    1.0\n",
            "9509    1.0\n",
            "Name: Class, Length: 530, dtype: float64\n",
            "(530, 30) (424, 30) (106, 30)\n",
            "Accuracy on Training data :  1.0\n",
            "Accuracy score on Test Data :  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    }
  ]
}